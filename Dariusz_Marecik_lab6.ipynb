{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "49f56df6",
   "metadata": {},
   "source": [
    "# LABORATORIUM 6 - SVD: Zastosowania\n",
    "\n",
    "Autor: **Dariusz Marecik**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee5fbfc0",
   "metadata": {},
   "source": [
    "Github link: https://github.com/FloudMe77/SimpleWikiSearch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e29d5f34",
   "metadata": {},
   "source": [
    "Celem projektu jest stworzenie wyszukiwarki artykułów wykorzystującej redukcję szumu za pomocą metody SVD."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6b3dced",
   "metadata": {},
   "source": [
    "# Zbiory artykułów"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bb19218",
   "metadata": {},
   "source": [
    "Na potrzeby testów przygotowałem trzy zestawy artykułów, które zostały zapisane w plikach ```.db``` z wykorzystaniem struktury bazy danych SQLite."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "378b62ef",
   "metadata": {},
   "source": [
    "## Tworzenie bazy danych na podstawie gotowej paczki artykułów"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "248ba4f2",
   "metadata": {},
   "source": [
    "Projekt rozpocząłem od wykorzystania artykułów z serwisu ```simple.wikipedia.org```. W tym celu pobrałem plik ```.xml``` z pełną zawartością bazy artykułów i poddałem go przetwarzaniu, przygotowując dane do zaimportowania do własnej bazy danych."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d14a9ecf",
   "metadata": {},
   "source": [
    "Plik ```dump_loader.py```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1631d88a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mwxml\n",
    "import mwparserfromhell\n",
    "import sqlite3\n",
    "import re\n",
    "\n",
    "conn = sqlite3.connect('simplewiki2.db')\n",
    "c = conn.cursor()\n",
    "c.execute('''CREATE TABLE IF NOT EXISTS articles (\n",
    "                id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "                url TEXT,\n",
    "                title TEXT,\n",
    "                intro TEXT,\n",
    "                content TEXT\n",
    "            )''')\n",
    "conn.commit()\n",
    "\n",
    "def clean_text(wiki_text):\n",
    "    # Parsowanie i usuwanie kodu wiki\n",
    "    wikicode = mwparserfromhell.parse(wiki_text)\n",
    "    text = wikicode.strip_code()\n",
    "\n",
    "    # Usuwanie niechcianych linii (thumb, right, left, center, itp.)\n",
    "    text = re.sub(r'^.*\\b(?:thumb|right|left|center)\\b.*$', '', text, flags=re.MULTILINE)\n",
    "\n",
    "    # Usuwanie nadmiarowych nowych linii, spacji i tabulatorów\n",
    "    text = re.sub(r'[ \\t]+', ' ', re.sub(r'\\n{2,}', '\\n\\n', text))\n",
    "\n",
    "    # Usuwanie resztek formatowania\n",
    "    text = re.sub(r'\\b(?:[0-9]+\\s*px|[0-9]+x[0-9]+px|thumb|right|left|center)\\b\\|?', '', text, flags=re.IGNORECASE)\n",
    "\n",
    "    return text.strip()\n",
    "\n",
    "def count_words(text):\n",
    "    return len(re.findall(r'\\b\\w+\\b', text))\n",
    "\n",
    "def main():\n",
    "    dump_path = \"dump/simplewiki-latest-pages-articles.xml\"\n",
    "    cnt = 0\n",
    "    with open(dump_path, 'r', encoding='utf-8') as f:\n",
    "        dump = mwxml.Dump.from_file(f)\n",
    "\n",
    "        # transakcje dla większej wydajności\n",
    "        c.execute('BEGIN TRANSACTION;')\n",
    "\n",
    "        for page in dump.pages:\n",
    "            if page.redirect is not None or page.namespace != 0:\n",
    "                continue  # pomijamy przekierowania i inne przestrzenie nazw\n",
    "\n",
    "            for revision in page:\n",
    "                title = page.title\n",
    "                wiki_text = revision.text\n",
    "                if not wiki_text:\n",
    "                    continue\n",
    "\n",
    "                clean = clean_text(wiki_text)\n",
    "                if count_words(clean) < 100:\n",
    "                    continue  \n",
    "\n",
    "                if cnt % 1000 == 0:\n",
    "                    print(f'Przetworzono {cnt} artykułów')\n",
    "\n",
    "                cnt += 1\n",
    "\n",
    "                intro = clean.split(\"\\n\\n\")[0].strip()\n",
    "\n",
    "                url = f\"https://simple.wikipedia.org/wiki/{title.replace(' ', '_')}\"\n",
    "\n",
    "                c.execute('''\n",
    "                    INSERT INTO articles (url, title, intro, content)\n",
    "                    VALUES (?, ?, ?, ?)\n",
    "                ''', (url, title, intro, clean))\n",
    "\n",
    "                # Commit co 1000 artykułów\n",
    "                if cnt % 1000 == 0:\n",
    "                    conn.commit()\n",
    "\n",
    "        # Zakończenie transakcji po przetworzeniu wszystkich stron\n",
    "        c.execute('COMMIT;')\n",
    "\n",
    "    conn.close()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94ad6a77",
   "metadata": {},
   "source": [
    "W wyniku przetwarzania danych powstały dwie bazy: jedna zawierająca artykuły o długości przekraczającej 100 słów (127 tys. rekordów) oraz druga z artykułami mającymi ponad 200 słów (63 tys. rekordów)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e075c785",
   "metadata": {},
   "source": [
    "## Crawlowanie oraz Scrapowanie Sieci"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dc6ee4c",
   "metadata": {},
   "source": [
    "**Drugim zbiorem jaki chciałem przygotować były artykuły z dziedziny szeroko pojętej historii. W tym celu postanowiłem pobrać artykuły bezpośrednio ze stron wikipedii.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7090e267",
   "metadata": {},
   "source": [
    "### Opis działania skryptu scrapującego artykuły historyczne z Wikipedii\n",
    "\n",
    "Skrypt służy do automatycznego pobierania i zapisywania artykułów związanych z historią z anglojęzycznej Wikipedii. Wykorzystuje techniki web scrapingu oraz filtrację na podstawie słów kluczowych (np. *war*, *empire*, *revolution*, *medieval*), tworząc specjalistyczną bazę danych tekstów historycznych w formacie SQLite (```historywiki.db```).\n",
    "\n",
    "Działanie programu rozpoczyna się od zadanej strony startowej (w tym przypadku:\n",
    "```https://en.wikipedia.org/wiki/Category:History_by_location```), a następnie rekurencyjnie przeszukuje powiązane linki do ustalonej głębokości. Każdy artykuł jest analizowany, a jego zawartość oczyszczana z przypisów, znaczników i zbędnych znaków.\n",
    "\n",
    "Aby umożliwić wznawianie pracy po przerwie, skrypt cyklicznie zapisuje swój stan (kolejkę URL-i, liczniki) do pliku .pkl z użyciem biblioteki pickle. Dodatkowo stosowane są losowe opóźnienia między zapytaniami, by nie przeciążać serwerów Wikipedii.\n",
    "\n",
    "Do bazy danych jest zapisywana cała treść artykułu, bez usuwania stopwords, czy innych elementów preprocesingu.\n",
    "\n",
    "#### Schemat działania algorytmu\n",
    "\n",
    "1. **Start**\n",
    "\n",
    "   * Ustawienie strony początkowej:\n",
    "     `https://en.wikipedia.org/wiki/Category:History_by_location`\n",
    "   * Wczytanie lub inicjalizacja kolejki URL-i i stanu z pliku `.pkl`.\n",
    "\n",
    "2. **Przeszukiwanie**\n",
    "\n",
    "   * Rekurencyjne odwiedzanie stron do zadanej głębokości.\n",
    "   * Filtrowanie linków na podstawie słów kluczowych w tytule i kategoriach.\n",
    "   * Dodawanie nowych linków do kolejki.\n",
    "\n",
    "3. **Pobieranie treści**\n",
    "\n",
    "   * Dla zakwalifikowanych artykułów: tytuł, lead, pełna treść.\n",
    "\n",
    "4. **Czyszczenie i zapis**\n",
    "\n",
    "   * Usuwanie przypisów, tagów, nadmiarowych spacji.\n",
    "   * Zapis do bazy `historywiki.db`.\n",
    "\n",
    "5. **Zarządzanie stanem i etykieta**\n",
    "\n",
    "   * Zapisywanie stanu do `.pkl`.\n",
    "   * Losowe opóźnienia między zapytaniami.\n",
    "\n",
    "Ostatecznie udało się pobrać ok 90 tys. artykułów\n",
    "\n",
    "Plik ```scraper.py```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "861a53a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import sqlite3\n",
    "from urllib.parse import quote\n",
    "import re\n",
    "import time\n",
    "from urllib.parse import urlparse, unquote\n",
    "from collections import deque\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "KEYWORDS = {\n",
    "    'history', 'historical', 'historian', 'historiography', 'ancient', 'medieval', \n",
    "    'renaissance', 'enlightenment', 'modern', 'prehistoric', 'neolithic', \n",
    "    'bronze age', 'iron age', 'classical', 'middle ages', 'dark ages', \n",
    "    'colonial', 'victorian', 'industrial', 'postmodern', 'contemporary', \n",
    "    'century', 'millennium', 'era', 'period', 'antiquity', 'prehistoric', \n",
    "    'pre-columbian', 'post-war', 'interwar', 'war', 'battle', 'siege', \n",
    "    'invasion', 'conquest', 'conflict', 'crusade', 'rebellion', 'revolt', \n",
    "    'uprising', 'insurrection', 'civil war', 'world war', 'campaign', \n",
    "    'revolution', 'insurgency', 'raid', 'guerrilla', 'occupation', \n",
    "    'resistance', 'combat', 'skirmish', 'offensive', 'warfare', 'empire', \n",
    "    'kingdom', 'dynasty', 'monarchy', 'republic', 'state', 'nation', \n",
    "    'civilization', 'colony', 'realm', 'territory', 'commonwealth', 'province', \n",
    "    'principality', 'duchy', 'sultanate', 'caliphate', 'confederation', \n",
    "    'federation', 'union', 'horde', 'khanate', 'shogunate', 'chiefdom'\n",
    "}\n",
    "\n",
    "def save_data(Q, visited, cnt):\n",
    "    with open(\"saved_data/scraper3.pkl\", \"wb\") as f:\n",
    "            pickle.dump({\n",
    "                \"Q\": Q,\n",
    "                \"visited\": visited,\n",
    "                \"cnt\": cnt\n",
    "            }, f)\n",
    "def read_data():\n",
    "    with open(\"saved_data/scraper3.pkl\", \"rb\") as f:\n",
    "            data = pickle.load(f)\n",
    "            Q = data[\"Q\"]\n",
    "            visited = data[\"visited\"]\n",
    "            cnt = data[\"cnt\"]\n",
    "    return Q, visited, cnt\n",
    "\n",
    "def get_title_from_url(url):\n",
    "    path = urlparse(url).path \n",
    "    title = path.split('/')[-1] \n",
    "    return unquote(title.replace('_', ' ')) \n",
    "\n",
    "conn = sqlite3.connect('historywiki.db')\n",
    "c = conn.cursor()\n",
    "c.execute('''CREATE TABLE IF NOT EXISTS articles (\n",
    "                id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "                url TEXT,\n",
    "                title TEXT,\n",
    "                intro TEXT,\n",
    "                content TEXT\n",
    "            )''')\n",
    "conn.commit()\n",
    "\n",
    "def clean_wikipedia_text(text):\n",
    "    # 1. Wyciągamy główną treść artykułu\n",
    "    match = re.search(\n",
    "        r\"From Wikipedia, the free encyclopedia(.*)\",\n",
    "        text,\n",
    "        re.DOTALL\n",
    "    )\n",
    "    content = match.group(1) if match else text\n",
    "\n",
    "    # 2. Usuwamy przypisy w nawiasach kwadratowych, np. [1], [b]\n",
    "    content = re.sub(r\"\\[\\w{1,3}\\]\", \"\", content)\n",
    "\n",
    "    # 3. Usuwamy fragmenty zawierające \"vte\"\n",
    "    content = re.sub(r\"\\bvte\\b\", \"\", content)\n",
    "\n",
    "    # 4. Rozdzielamy camelCase / PascalCase np. \"CategoryReferance\" → \"Category Referance\"\n",
    "    content = re.sub(r\"(?<=[a-z])(?=[A-Z])\", \" \", content)\n",
    "\n",
    "    # 5. Usuwamy nadmiarowe spacje i taby\n",
    "    content = re.sub(r\"[ \\t]{2,}\", \" \", content)\n",
    "\n",
    "    # 6. Redukujemy wiele nowych linii do pojedynczego\n",
    "    content = re.sub(r\"\\n{2,}\", \"\\n\", content)\n",
    "\n",
    "    # 7. Usuwamy puste linie i whitespace\n",
    "    content = \"\\n\".join(line.strip() for line in content.splitlines() if line.strip())\n",
    "\n",
    "    return content\n",
    "\n",
    "def is_history_related(title):\n",
    "    return any(keyword in title.lower() for keyword in KEYWORDS)\n",
    "\n",
    "def get_content(content, content_div, url, title):\n",
    "    content = clean_wikipedia_text(content)\n",
    "\n",
    "    # Inicjalizacja intro_paragraphs\n",
    "    intro_paragraphs = \"\"\n",
    "    \n",
    "    if content_div:\n",
    "        for elem in content_div.find_all(['p', 'h2']):\n",
    "            if elem.name == 'p':\n",
    "                text = elem.get_text(strip=True)\n",
    "                if text and len(text) > 70:\n",
    "                    intro_paragraphs = text\n",
    "                    break\n",
    "                    \n",
    "        # Sprawdź czy artykuł już istnieje w bazie danych\n",
    "        c.execute(\"SELECT id FROM articles WHERE url = ?\", (url,))\n",
    "        existing = c.fetchone()\n",
    "        \n",
    "        if not existing:  # Zapisz tylko jeśli nie istnieje\n",
    "            c.execute('''\n",
    "                INSERT INTO articles (url, title, intro, content)\n",
    "                VALUES (?, ?, ?, ?)\n",
    "            ''', (url, title, intro_paragraphs, content))\n",
    "            conn.commit()\n",
    "            print(f\"Zapisano artykuł: {title}\")\n",
    "        else:\n",
    "            print(f\"Artykuł już istnieje w bazie: {title}\")\n",
    "\n",
    "def search(url, maxdepth, read = False):\n",
    "\n",
    "    Q = deque()\n",
    "    Q.append((url,0))\n",
    "    visited = set()\n",
    "    cnt=0\n",
    "    last_request_start_time = time.time()\n",
    "    if read:\n",
    "        Q,visited,cnt = read_data()\n",
    "    while Q:\n",
    "        url,depth = Q.pop()\n",
    "        \n",
    "        if depth > maxdepth or url in visited:\n",
    "            continue\n",
    "            \n",
    "        print(f\"Przetwarzanie: {url} (głębokość: {depth})\")\n",
    "        visited.add(url)\n",
    "        current_time = time.time()\n",
    "        time_since_last_start = current_time - last_request_start_time\n",
    "        \n",
    "        desired_interval = np.random.uniform(0.4, 0.6)\n",
    "        \n",
    "        sleep_duration = desired_interval - time_since_last_start\n",
    "        \n",
    "        if sleep_duration > 0:\n",
    "            time.sleep(sleep_duration)\n",
    "            \n",
    "        # Zapisz czas tuż przed wysłaniem nowego requestu\n",
    "        last_request_start_time = time.time() \n",
    "        \n",
    "        try:\n",
    "            headers = {\n",
    "                'User-Agent': 'own project HistoryWikiSearch/1.0',\n",
    "                'From': 'marecik7@gmail.com' \n",
    "            }\n",
    "\n",
    "            r = requests.get(url, headers=headers)\n",
    "            r.raise_for_status()\n",
    "        except requests.RequestException as e:\n",
    "            print(f\"Błąd pobierania {url}: {e}\")\n",
    "            continue\n",
    "        cnt+=1\n",
    "        if cnt%100 ==0:\n",
    "            save_data(Q, visited, cnt)\n",
    "        \n",
    "        \n",
    "        soup = BeautifulSoup(r.text, 'html.parser')\n",
    "        content_div = soup.find('div', {'id': 'mw-content-text'})\n",
    "        \n",
    "        if not content_div:\n",
    "            continue\n",
    "            \n",
    "        # Sprawdź, czy to jest artykuł o historii i zapisz go\n",
    "        title = get_title_from_url(url)\n",
    "        if is_history_related(title) and not url.startswith('https://en.wikipedia.org/wiki/Category:'):\n",
    "            get_content(soup.get_text(), content_div, url, title)\n",
    "        \n",
    "        # Przeszukaj linki na stronie\n",
    "        else:\n",
    "            for link in content_div.find_all('a')[::-1]:\n",
    "                href = link.get('href')\n",
    "                if href and href.startswith('/wiki/'):\n",
    "                    rest = href[6:]\n",
    "                    full_url = 'https://en.wikipedia.org' + href\n",
    "                    \n",
    "                    # Jeśli to kategoria, przejdź do niej\n",
    "                    if rest.startswith('Category:') and any(keyword in rest.lower() for keyword in KEYWORDS):\n",
    "                        Q.append((full_url,depth + 1))\n",
    "                        \n",
    "                    # Jeśli to artykuł związany z historią, dodaj go do kolejki\n",
    "                    elif is_history_related(rest) and not any(rest.startswith(prefix) for prefix in ['Wikipedia:', 'Special:', 'File:', 'Help:', 'Template:']):\n",
    "                        if depth < maxdepth:\n",
    "                            Q.append((full_url,depth + 1))\n",
    "                        \n",
    "                    \n",
    "    return cnt\n",
    "\n",
    "def main():\n",
    "    print(\"Rozpoczynam pobieranie artykułów z Wikipedii\")\n",
    "    \n",
    "    # Początkowa strona kategorii\n",
    "    start_url = \"https://en.wikipedia.org/wiki/Category:History_by_location\"\n",
    "    \n",
    "    # Maksymalna głębokość przeszukiwania\n",
    "    max_depth = 5\n",
    "    \n",
    "    # Rozpocznij przeszukiwanie\n",
    "    found_urls = search(start_url, max_depth)\n",
    "    \n",
    "    print(f\"Znaleziono {found_urls} artykułów związanych z historią\")\n",
    "    \n",
    "    conn.close()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c89a6a47",
   "metadata": {},
   "source": [
    "# Przetwarzanie tekstów artykułów"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "857ead1f",
   "metadata": {},
   "source": [
    "Aby zredukować rozmiar macierzy Bag of Words oraz poprawić jakość wyników wyszukiwania, zaimplementowałem funkcję, która przetwarza tekst w następujący sposób:\n",
    "\n",
    "* Tokenizuje tekst, dzieląc go na pojedyncze słowa,\n",
    "* Zamienia wszystkie słowa na małe litery,\n",
    "* Lematyzuje słowa, sprowadzając je do formy podstawowej (np. \"cats\" -> \"cat\"),\n",
    "* Usuwa słowa, które nie są rzeczywistymi wyrazami (np. cyfry, liczby, znaki specjalne).\n",
    "\n",
    "Plik ```simplifier.py```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a16bf2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize \n",
    "\n",
    "try:\n",
    "    stopwords.words('english')\n",
    "except LookupError:\n",
    "    nltk.download('stopwords')\n",
    "try:\n",
    "    word_tokenize(\"test\")\n",
    "except LookupError:\n",
    "    nltk.download('punkt') \n",
    "try:\n",
    "    nltk.pos_tag([\"test\"])\n",
    "except LookupError:\n",
    "    nltk.download('averaged_perceptron_tagger') \n",
    "try:\n",
    "    WordNetLemmatizer().lemmatize(\"cars\")\n",
    "except LookupError:\n",
    "    nltk.download('wordnet')\n",
    "\n",
    "\n",
    "class Simplifier:\n",
    "    def __init__(self):\n",
    "        self.lemmatizer = WordNetLemmatizer()\n",
    "        self.stop_words = set(stopwords.words('english'))\n",
    "        # Mapa tagów POS dla lematyzatora\n",
    "        self.pos_map = {\n",
    "            'NN': 'n', 'NNS': 'n', 'NNP': 'n', 'NNPS': 'n', # Noun\n",
    "            'VB': 'v', 'VBD': 'v', 'VBG': 'v', 'VBN': 'v', 'VBP': 'v', 'VBZ': 'v', # Verb\n",
    "            'JJ': 'a', 'JJR': 'a', 'JJS': 'a', # Adjective\n",
    "            'RB': 'r', 'RBR': 'r', 'RBS': 'r'  # Adverb\n",
    "        }\n",
    "\n",
    "    def simplify_words(self, content):\n",
    "        words = word_tokenize(content)\n",
    "        \n",
    "        tagged_words = nltk.pos_tag(words)\n",
    "        \n",
    "        simplified_lemmas = []\n",
    "        for word, tag in tagged_words:\n",
    "            word_lower = word.lower()\n",
    "            \n",
    "            # Filtrowanie stop-wordów i tokenów niealfabetycznych\n",
    "            if word_lower not in self.stop_words and word.isalpha():\n",
    "                # Domyślnie użyj 'n' (rzeczownik), jeśli tag nie jest w mapie\n",
    "                pos_tag_for_lemmatizer = self.pos_map.get(tag[:2], 'n')\n",
    "                lemma = self.lemmatizer.lemmatize(word_lower, pos=pos_tag_for_lemmatizer)\n",
    "                \n",
    "                simplified_lemmas.append(lemma)\n",
    "                    \n",
    "        return simplified_lemmas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99ea4e0b",
   "metadata": {},
   "source": [
    "## Klasa pomocnicza (databse_manager)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10e002a5",
   "metadata": {},
   "source": [
    "Dla polepszenia estetyki kodu stworzyłem klasę pomocniczą do obsługi bazy danych.\n",
    "\n",
    "Plik ```databse_manager.py```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ee3d407",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "\n",
    "class DatabaseManager:\n",
    "    def __init__(self,database_name):\n",
    "        self.database_name = database_name\n",
    "    \n",
    "    def get_connection(self):\n",
    "        return sqlite3.connect(f\"{self.database_name}.db\")\n",
    "    \n",
    "    def get_data(self,items, index_tab):\n",
    "        with self.get_connection() as conn:\n",
    "            cursor = conn.cursor()\n",
    "            placeholders = ','.join(str(i + 1) for i in index_tab)\n",
    "            query = f\"SELECT {items} FROM articles WHERE id IN ({placeholders})\"\n",
    "            return cursor.execute(query).fetchall()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30658034",
   "metadata": {},
   "source": [
    "# Główny silnik wyszukiwarki"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21dd24ae",
   "metadata": {},
   "source": [
    "### Opis:\n",
    "\n",
    "Program implementuje system wyszukiwania dokumentów oparty na technikach przetwarzania tekstu i redukcji wymiarów (SVD), który pozwala na efektywne wyszukiwanie artykułów na podstawie zapytań. Wykorzystuje macierz Bag of Words (BoW) oraz opcjonalnie dekompozycję SVD do redukcji wymiarów i indeksowanie HNSW w celu szybszego wyszukiwania.\n",
    "\n",
    "### Kroki, które wykonuje program:\n",
    "\n",
    "1. **Inicjalizacja:**\n",
    "\n",
    "   * Sprawdza, czy zapisane dane (macierz BoW oraz struktury słów) istnieją, jeśli tak, to je wczytuje, w przeciwnym razie przygotowuje dane do analizy.\n",
    "\n",
    "2. **Dodawanie artykułów:**\n",
    "\n",
    "   * Przetwarza artykuł, rozdzielając tekst na słowa, lematyzując je, a następnie tworzy reprezentację macierzy termów (BoW) dla danego dokumentu.\n",
    "\n",
    "3. **Tworzenie macierzy BoW:**\n",
    "\n",
    "   * Buduje rzadką macierz BoW, zawierającą liczbę wystąpień słów w dokumentach.\n",
    "\n",
    "4. **Obliczanie TF-IDF:**\n",
    "\n",
    "   * Oblicza ważność słów za pomocą IDF i normalizuje dokumenty, tworząc znormalizowaną macierz TF-IDF.\n",
    "\n",
    "5. **Obsługa zapytań:**\n",
    "\n",
    "   * Dla zapytania oblicza podobieństwo z dokumentami za pomocą macierzy BoW lub przestrzeni zredukowanej (SVD), zwracając najbardziej podobne artykuły.\n",
    "\n",
    "6. **Redukcja wymiarów (SVD):**\n",
    "\n",
    "   * Jeśli włączona jest opcja SVD, wykonuje dekompozycję macierzy BoW, a następnie używa zredukowanej przestrzeni wektorowej do szybszego wyszukiwania przy użyciu indeksu HNSW.\n",
    "\n",
    "7. **Indeksowanie HNSW:**\n",
    "\n",
    "   * Buduje i wykorzystuje indeks HNSW (Hierarchical Navigable Small World) w celu przyspieszenia wyszukiwania podobnych dokumentów w zredukowanej przestrzeni.\n",
    "\n",
    "8. **Zapis i odczyt danych:**\n",
    "\n",
    "   * Program zapisuje i wczytuje macierze BoW oraz wyniki dekompozycji SVD do plików w celu późniejszego użycia.\n",
    "\n",
    "9. **Normalizacja zapytania:**\n",
    "\n",
    "   * Przed obliczeniem podobieństwa zapytanie jest normalizowane, aby uzyskać spójne wyniki.\n",
    "\n",
    "Początkowo macierz BOW jest trzymana jako lista krotek, później jest konwertowana do csc_matrix. Obsługiwane jest działanie wyszukiwarki z SVD + HNSW oraz bez tych struktur.\n",
    "\n",
    "plik ```search_engine.py```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2740787",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from scipy.sparse import csr_matrix, csc_matrix, diags, linalg\n",
    "import numpy as np\n",
    "import heapq\n",
    "from sklearn.preprocessing import normalize\n",
    "from scipy.sparse import save_npz, load_npz\n",
    "import pickle\n",
    "from scipy.sparse.linalg import svds\n",
    "import simplifier\n",
    "import hnswlib\n",
    "import os\n",
    "\n",
    "class Engine:\n",
    "\n",
    "    def __init__(self, database_name = '', svd_on = False, k = None):\n",
    "        # svd_on - determinuje, czy używamy svd przy wyszukiwaniu, czy nie\n",
    "        # k - liczba największych wartości osobliwych (singular values) w SVD\n",
    "\n",
    "        word_matrix_path = f\"saved_data/csc_BOW_{database_name}.npz\"\n",
    "        word_structures_path = f\"saved_data/word_structures_{database_name}.pkl\"\n",
    "        self.is_matrix_saved = self.file_exist(word_matrix_path) and self.file_exist(word_structures_path)\n",
    "        self.database_name = database_name\n",
    "\n",
    "        if self.is_matrix_saved:\n",
    "            self.read_BOW_from_file()\n",
    "        else:\n",
    "            print(self.file_exist(word_matrix_path))\n",
    "            print(self.file_exist(word_structures_path))\n",
    "            self.number_to_word = []\n",
    "            self.word_to_number = dict()\n",
    "            self.tuple_BOW = []\n",
    "            self.n_articles = 0\n",
    "            self.csc_BOW = None \n",
    "            self.articles_with_word = defaultdict(int)\n",
    "            self.simplifier = simplifier.Simplifier()\n",
    "        \n",
    "        \n",
    "        self.svd_on = svd_on\n",
    "        self.k = k\n",
    "\n",
    "    def file_exist(self,path_name):\n",
    "        return os.path.exists(path_name) and os.path.isfile(path_name)\n",
    "\n",
    "    def content_to_tuple_matrix(self, words, id):\n",
    "        unique_words = set()\n",
    "        counts = defaultdict(int)\n",
    "        for word in words:\n",
    "            if word not in self.word_to_number:\n",
    "                # następny wolny numerek\n",
    "                self.word_to_number[word] = len(self.number_to_word)\n",
    "                self.number_to_word.append(word)\n",
    "\n",
    "            if word not in unique_words:\n",
    "                # inkrementacja liczby artykułów z tym słowem\n",
    "                self.articles_with_word[word] += 1\n",
    "                unique_words.add(word)\n",
    "                \n",
    "            counts[self.word_to_number[word]] += 1\n",
    "            \n",
    "        return [(id, col, val) for col, val in counts.items()]\n",
    "\n",
    "    def add_article(self, id, content):\n",
    "        words = self.simplifier.simplify_words(content)\n",
    "        # indeksy w bazie danych zaczynają się od 1, a w macierzy od 0\n",
    "        new_tuples = self.content_to_tuple_matrix(words, id-1)\n",
    "        \n",
    "        self.tuple_BOW.extend(new_tuples)\n",
    "        self.n_articles += 1\n",
    "\n",
    "    def create_csr_matrix(self):\n",
    "        print(\"start_create_csr_matrix\")\n",
    "        \n",
    "        if not self.tuple_BOW:\n",
    "            return csr_matrix((0, 0))\n",
    "        \n",
    "        rows, cols, data = zip(*self.tuple_BOW)\n",
    "        shape = (self.n_articles, max(cols) + 1)\n",
    "        print(\"end_create_csr_matrix\")\n",
    "        return csr_matrix((data, (rows, cols)), shape=shape)\n",
    "\n",
    "    def start_engine(self):\n",
    "        if not self.is_matrix_saved:\n",
    "            self.IDF_and_normalization()\n",
    "            self.save_BOW_to_file()\n",
    "\n",
    "        if self.svd_on:\n",
    "            if self.file_exist(f\"saved_svd/svd{self.k}_{self.database_name}.pkl\"):\n",
    "                self.read_SVD_from_file()\n",
    "            else:\n",
    "                self.lower_rank()\n",
    "\n",
    "    def IDF_and_normalization(self):\n",
    "        print(\"start idf\")\n",
    "\n",
    "        self.csc_BOW = self.create_csr_matrix()  # ustawia self.csc_BOW (TF)\n",
    "\n",
    "        self.info()\n",
    "\n",
    "        N = self.csc_BOW.shape[0]  # liczba dokumentów\n",
    "        M = self.csc_BOW.shape[1]  # liczba słów\n",
    "\n",
    "        idf = [np.log(N / self.articles_with_word[self.number_to_word[i]]) for i in range(M)]\n",
    "        self.idf_diag = diags(idf)\n",
    "        tf_idf = self.csc_BOW @ self.idf_diag\n",
    "\n",
    "        # Transpozycja: wiersze = słowa, kolumny = dokumenty\n",
    "        tf_idf = tf_idf.T\n",
    "\n",
    "        # Normalizacja  dokumentów\n",
    "        tf_idf = normalize(tf_idf, axis=0, norm='l2')\n",
    "        self.csc_BOW = tf_idf \n",
    "        print(\"end idf\")\n",
    "\n",
    "    def handleQuery(self, query_vector, top):\n",
    "        # w zależności czy svd\n",
    "        return self.handleQueryUVD(query_vector, top) if self.svd_on else self.handleQueryNormal(query_vector, top)\n",
    "    \n",
    "\n",
    "    def handleQueryNormal(self, query_vector, top):\n",
    "        normalized_query = query_vector / linalg.norm(query_vector)\n",
    "        result = np.abs((normalized_query.T @ self.csc_BOW)).T  # (N, 1)\n",
    "        similarities = result.flatten()\n",
    "        top_indices = heapq.nlargest(top, range(len(similarities)), key=lambda i: similarities[i])\n",
    "\n",
    "        return [(i, round(similarities[i]*100,1)) for i in top_indices]\n",
    "    \n",
    "    def lower_rank(self):\n",
    "        print(\"start decomposition\")\n",
    "        U, D, Vt = svds(self.csc_BOW, k=self.k)\n",
    "\n",
    "        self.U = U\n",
    "        self.Vt = Vt\n",
    "        self.D = diags(D)\n",
    "        self.D_values = D.astype('float32')  # przyda się później\n",
    "\n",
    "        # Przekształcamy dokumenty do przestrzeni zredukowanej\n",
    "        X_reduced = (np.diag(D) @ Vt).T.astype('float32')  # shape: (n_docs, k)\n",
    "\n",
    "        # Budujemy HNSW index\n",
    "        dim = self.k\n",
    "        self.index = hnswlib.Index(space='cosine', dim=dim)\n",
    "        self.index.init_index(max_elements=X_reduced.shape[0], ef_construction=200, M=32)\n",
    "        self.index.add_items(X_reduced)\n",
    "        self.index.set_ef(200)\n",
    "\n",
    "        print(\"end decomposition + HNSW\")\n",
    "        self.save_SVD_to_file()\n",
    "\n",
    "    def handleQueryUVD(self, query_vector, top=10):\n",
    "        # if self.idf_diag:\n",
    "        #     query_vector = self.idf_diag @ query_vector\n",
    "\n",
    "        norm = linalg.norm(query_vector)\n",
    "        if norm == 0:\n",
    "            return []\n",
    "\n",
    "        normalized_query = query_vector / norm\n",
    "\n",
    "        q = self.U.T @ normalized_query  \n",
    "        q = self.D @ q\n",
    "        q_dense = q.flatten().astype('float32').reshape(1, -1)\n",
    "\n",
    "        # Szukanie przez HNSW\n",
    "        labels, distances = self.index.knn_query(q_dense, k=top)\n",
    "\n",
    "        return [(int(i), round((1 - d) * 100, 1)) for i, d in zip(labels[0], distances[0])]\n",
    "\n",
    "    def info(self):\n",
    "        print(self.csc_BOW.shape)\n",
    "    \n",
    "    def save_BOW_to_file(self):\n",
    "        print(\"start saving BOW\")\n",
    "\n",
    "        save_npz(f\"saved_data/csc_BOW_{self.database_name}.npz\", self.csc_BOW)\n",
    "        with open(f\"saved_data/word_structures_{self.database_name}.pkl\", \"wb\") as f:\n",
    "            pickle.dump({\n",
    "                \"number_to_word\": self.number_to_word,\n",
    "                \"word_to_number\": self.word_to_number,\n",
    "                \"idf_diag\": self.idf_diag\n",
    "            }, f)\n",
    "        print(\"end saving BOW\")\n",
    "\n",
    "    def read_BOW_from_file(self):\n",
    "        print(\"start reading BOW\")\n",
    "\n",
    "        self.csc_BOW = load_npz(f\"saved_data/csc_BOW_{self.database_name}.npz\")\n",
    "        with open(f\"saved_data/word_structures_{self.database_name}.pkl\", \"rb\") as f:\n",
    "            data = pickle.load(f)\n",
    "            self.number_to_word = data[\"number_to_word\"]\n",
    "            self.word_to_number = data[\"word_to_number\"]\n",
    "            if \"idf_diag\" in data:\n",
    "                self.idf_diag = data[\"idf_diag\"]\n",
    "            else:\n",
    "                self.idf_diag = None\n",
    "        print(\"end reading BOW\")\n",
    "\n",
    "    def save_SVD_to_file(self):\n",
    "        print(\"start saving SVD\")\n",
    "\n",
    "        with open(f\"saved_svd/svd{self.k}_{self.database_name}.pkl\", \"wb\") as f:\n",
    "            pickle.dump({\n",
    "                \"U\": self.U,\n",
    "                \"D\": self.D,\n",
    "                \"Vt\": self.Vt,\n",
    "                \"index\": self.index\n",
    "            }, f)\n",
    "        print(\"end saving SVD\")\n",
    "\n",
    "    def read_SVD_from_file(self):\n",
    "        print(\"start reading SVD\")\n",
    "        with open(f\"saved_svd/svd{self.k}_{self.database_name}.pkl\", \"rb\") as f:\n",
    "            data = pickle.load(f)\n",
    "            self.U = data[\"U\"]\n",
    "            self.D = data[\"D\"]\n",
    "            self.Vt = data[\"Vt\"]\n",
    "            self.index = data[\"index\"]\n",
    "        print(\"end reading SVD\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ed6e149",
   "metadata": {},
   "source": [
    "# Zarządzanie silnikiem wyszukiwania"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c46efaab",
   "metadata": {},
   "source": [
    "Klasa Search_engine_manager stanowi warstwę pośrednią między użytkownikiem a silnikiem wyszukiwania tekstów opartych na bazie danych artykułów historycznych. Obsługuje zarówno przetwarzanie zapytań użytkownika, jak i inicjalizację oraz ładowanie danych do silnika wyszukiwania.\n",
    "\n",
    "Główne funkcje\n",
    "- Inicjalizacja silnika na podstawie bazy danych (SQLite), z opcjonalnym przetwarzaniem SVD (redukcją wymiarowości).\n",
    "\n",
    "- Przetwarzanie zapytań tekstowych użytkownika – upraszczanie, lematyzacja, konwersja do formy wektorowej.\n",
    "\n",
    "- Wyszukiwanie podobnych artykułów na podstawie obliczeń podobieństwa kosinusowego.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9de783e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import search_engine\n",
    "import sqlite3\n",
    "from collections import defaultdict\n",
    "from scipy.sparse import csc_matrix\n",
    "import simplifier\n",
    "\n",
    "class Search_engine_manager:\n",
    "    def __init__(self, database_name, start = True, svd_on = True, k = 300):\n",
    "        self.simplifier = simplifier.Simplifier()\n",
    "        self.database_name = database_name\n",
    "        self.en = search_engine.Engine(database_name = database_name, svd_on = svd_on, k = k)\n",
    "        if not start:\n",
    "            self.press_db_in_engine()\n",
    "        self.en.start_engine()\n",
    "\n",
    "    def parse_query(self, query):\n",
    "        words = self.simplifier.simplify_words(query)\n",
    "        counts = defaultdict(int)\n",
    "        for word in words:\n",
    "            if word in self.en.word_to_number:\n",
    "                counts[self.en.word_to_number[word]] += 1\n",
    "        indices, values = zip(*counts.items()) if counts else ([], [])\n",
    "        n_words = len(self.en.number_to_word)\n",
    "        return csc_matrix((values, (indices, [0] * len(indices))), shape=(n_words, 1))\n",
    "    \n",
    "    def hendle_query(self,query):\n",
    "        query_vector = self.parse_query(query)\n",
    "        return self.en.handleQuery(query_vector, 10)\n",
    "\n",
    "    def press_db_in_engine(self):\n",
    "        print(\"start parsing database\")\n",
    "        conn = sqlite3.connect(f\"{self.database_name}.db\")\n",
    "        cursor = conn.cursor()\n",
    "        cursor.execute('SELECT id, content FROM articles ')\n",
    "        for id,content in cursor.fetchall():\n",
    "            self.en.add_article(id,content)\n",
    "        print(\"Matrix built\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2b9d3a3",
   "metadata": {},
   "source": [
    "# Fronted wyszukiwarki"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f132601b",
   "metadata": {},
   "source": [
    "## Pliki html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb781e8e",
   "metadata": {},
   "source": [
    "Strona główna\n",
    "\n",
    "plik ```index.html```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d44df707",
   "metadata": {},
   "source": [
    "```\n",
    "<!DOCTYPE html>\n",
    "<html lang=\"en\">\n",
    "<head>\n",
    "    <meta charset=\"UTF-8\">\n",
    "    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n",
    "    <title>SimpleWikiSearch</title>\n",
    "    <link href=\"{{ url_for('static', filename='styles/style.css') }}\"\n",
    "          rel=\"stylesheet\" />\n",
    "</head>\n",
    "<body>\n",
    "    <h1>\n",
    "        <div class=\"card-logo\"> </div> SimpleWikiSearch\n",
    "    </h1>\n",
    "    <form action=\"/flask_app\" method=\"get\">\n",
    "        <input type=\"text\" name=\"fraze\" id=\"fraze\" placeholder=\"Enter phrase\" />\n",
    "        <button type=\"Search\">Search</button>\n",
    "    </form>\n",
    "</body>\n",
    "</html>\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "949172f7",
   "metadata": {},
   "source": [
    "Wyniki wyszukiwania\n",
    "\n",
    "plik ```search_result.html```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e65ef6b3",
   "metadata": {},
   "source": [
    "```\n",
    "<!DOCTYPE html>\n",
    "<html lang=\"en\">\n",
    "<head>\n",
    "    <meta charset=\"UTF-8\">\n",
    "    <meta name=\"viewport\" intro=\"width=device-width, initial-scale=1.0\">\n",
    "    <title>Results for {{ title }}</title>\n",
    "    <link href=\"{{ url_for('static', filename='styles/style.css') }}\" rel=\"stylesheet\" />\n",
    "</head>\n",
    "<body>\n",
    "    <h1>\n",
    "        <div class=\"card-logo\"> </div> SimpleWikiSearch\n",
    "        \n",
    "    </h1>\n",
    "    \n",
    "    <form action=\"/flask_app\" method=\"get\">\n",
    "        <input type=\"text\" name=\"fraze\" id=\"fraze\" placeholder=\"Enter phrase\" />\n",
    "        <button type=\"submit\">Submit</button>\n",
    "    </form>\n",
    "\n",
    "    <hr style=\"border: none; height: 1px; background-color: black; width: 50em;\">\n",
    "    <h3>Query: {{ title }}</h3>\n",
    "    <hr style=\"border: none; height: 1px; background-color: black; width: 50em;\">\n",
    "    <div class=\"search_result\">\n",
    "        {% for item in results %}\n",
    "        <div class = \"rate\">\n",
    "            \n",
    "        </div>\n",
    "        <div class = \"result\">\n",
    "            <P1>{{item.rate}}%</P1>\n",
    "            <h2> <a href=\"{{ item.url }}\">{{item.title}}</a> </h2>\n",
    "            <p2> {{item.intro}}</p2>\n",
    "        </div>\n",
    "        {% endfor %}\n",
    "    </div>\n",
    "</body>\n",
    "</html>\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41b2a250",
   "metadata": {},
   "source": [
    "Plik css\n",
    "\n",
    "Jeden wspólny dla każdego pliku html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90f96464",
   "metadata": {},
   "source": [
    "```\n",
    "/* Układ ogólny */\n",
    ".card-logo {\n",
    "    width: 30px;\n",
    "    height: 30px;\n",
    "    background-color: #4285f4;\n",
    "    border-radius: 50%;\n",
    "    margin-right: 15px;\n",
    "}\n",
    "\n",
    "body {\n",
    "    background-color: #fff;\n",
    "    font-family: Arial, sans-serif;\n",
    "    margin: 20;\n",
    "    padding: 20px;\n",
    "    display: flex;\n",
    "    flex-direction: column;\n",
    "    align-items: center;\n",
    "}\n",
    "\n",
    "/* Nagłówek wyników */\n",
    "h1 {\n",
    "    display: flex;\n",
    "    font-size: 2rem;\n",
    "    color: #202124;\n",
    "    margin-bottom: 2em;\n",
    "    align-items: center;\n",
    "}\n",
    "h3 {\n",
    "    font-size: 1.2rem;\n",
    "    color: #202124;\n",
    "    text-align: left; \n",
    "    border-bottom: 0;\n",
    "    border-top: 0;\n",
    "}\n",
    "\n",
    "/* Formularz wyszukiwania */\n",
    "form {\n",
    "    display: flex;\n",
    "    flex-direction: row;\n",
    "    justify-content: center;\n",
    "    align-items: center;\n",
    "    width: 100%;\n",
    "    max-width: 50em;\n",
    "    margin-bottom: 30px;\n",
    "}\n",
    "\n",
    "/* Pole wyszukiwania */\n",
    "input[type=\"text\"] {\n",
    "    flex: 1;\n",
    "    padding: 15px;\n",
    "    border: 2px solid #eee;\n",
    "    border-radius: 8px 0 0 8px;\n",
    "    font-size: 16px;\n",
    "    outline: none;\n",
    "}\n",
    "\n",
    "input[type=\"text\"]:hover {\n",
    "    box-shadow: 0 1px 4px rgba(121, 123, 128, 0.45);\n",
    "}\n",
    "\n",
    "input[type=\"text\"]:focus {\n",
    "    box-shadow: 0 1px 8px rgba(121, 123, 128, 0.45);\n",
    "}\n",
    "\n",
    "/* Przycisk */\n",
    "button {\n",
    "    padding: 15px 25px;\n",
    "    border: 2px solid #eee;\n",
    "    background-color: #4285f4;\n",
    "    color: white;\n",
    "    border: none;\n",
    "    border-radius: 0 8px 8px 0;\n",
    "    cursor: pointer;\n",
    "    font-size: 16px;\n",
    "}\n",
    "\n",
    "button:hover {\n",
    "    background-color: rgb(14, 140, 203);\n",
    "    box-shadow: 0 1px 8px rgba(121, 123, 128, 0.45);\n",
    "}\n",
    "\n",
    "/* Wyniki wyszukiwania */\n",
    ".search_result {\n",
    "    width: 100%;\n",
    "    max-width: 50em;\n",
    "}\n",
    "\n",
    "/* Każdy wynik */\n",
    ".result {\n",
    "    padding: 20px;\n",
    "    margin-bottom: 20px;\n",
    "    border-radius: 12px;\n",
    "    transition: box-shadow 0.3s ease;\n",
    "}\n",
    "\n",
    ".result:hover {\n",
    "    box-shadow: 0 2px 8px rgba(0,0,0,0.15);\n",
    "}\n",
    "\n",
    "/* Tytuł i link */\n",
    ".result h2 {\n",
    "    margin: 0 0 10px;\n",
    "    font-size: 1.2rem;\n",
    "    color: #1a0dab;\n",
    "}\n",
    "\n",
    ".result h2 a {\n",
    "    text-decoration: none;\n",
    "    color: inherit;\n",
    "}\n",
    "\n",
    ".result p2 {\n",
    "    display: -webkit-box;\n",
    "    -webkit-line-clamp: 2;       /* liczba linii */\n",
    "    -webkit-box-orient: vertical;\n",
    "    overflow: hidden;\n",
    "    text-overflow: ellipsis;\n",
    "    margin: 0;\n",
    "    color: #4d5156;\n",
    "    font-size: 14px;\n",
    "    line-height: 1.5;\n",
    "    \n",
    "}\n",
    ".result p1 {\n",
    "    color: #b13030;\n",
    "    font-size: 14px;\n",
    "    line-height: 1.5;\n",
    "}\n",
    "\n",
    "@media (max-width: 300px), (max-height: 300px) {\n",
    "    body {\n",
    "        background-color: #000;\n",
    "    }\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fef8e52c",
   "metadata": {},
   "source": [
    "## Serwer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a98a866",
   "metadata": {},
   "source": [
    "Prosty serwer obsługujący zapytania zadane przez użytkownika"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b0ed75b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask, render_template, request\n",
    "import search_engine_manager\n",
    "import sqlite3\n",
    "import database_manager\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "# Configuration\n",
    "DATABASE_NAME = 'simplewiki100'\n",
    "SEARCH_ENGINE = search_engine_manager.Search_engine_manager(DATABASE_NAME, svd_on=True, k=300)\n",
    "DB_MANAGER = database_manager.DatabaseManager(DATABASE_NAME)\n",
    "\n",
    "\n",
    "def get_data(items, index_tab):\n",
    "    \"\"\"Fetch data from the database based on given item fields and indices.\"\"\"\n",
    "    conn = sqlite3.connect(f\"{DATABASE_NAME}.db\")\n",
    "    cursor = conn.cursor()\n",
    "    placeholders = ','.join(str(i + 1) for i in index_tab)\n",
    "    query = f\"SELECT {items} FROM articles WHERE id IN ({placeholders})\"\n",
    "    return cursor.execute(query).fetchall()\n",
    "\n",
    "\n",
    "@app.route('/')\n",
    "@app.route('/index')\n",
    "def index():\n",
    "    \"\"\"Render the index page.\"\"\"\n",
    "    return render_template('index.html')\n",
    "\n",
    "\n",
    "@app.route('/flask_app')\n",
    "def get_search():\n",
    "    \"\"\"Handle search queries and render search results.\"\"\"\n",
    "    fraze = request.args.get(\"fraze\")\n",
    "    raw_data = SEARCH_ENGINE.hendle_query(fraze)\n",
    "    indexes, rates = zip(*raw_data)\n",
    "    indexes = list(indexes)\n",
    "    rates = list(rates)\n",
    "\n",
    "    results = [\n",
    "        {\"url\": url, \"title\": title, \"intro\": intro}\n",
    "        for url, title, intro in DB_MANAGER.get_data(\"url, title, intro\", indexes)\n",
    "    ]\n",
    "\n",
    "    for i, rate in enumerate(rates):\n",
    "        results[i][\"rate\"] = rate\n",
    "\n",
    "    return render_template(\"search_result.html\", title=fraze, results=results)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    app.run(host=\"0.0.0.0\", port=8000)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "785a264d",
   "metadata": {},
   "source": [
    "# Testowanie wyszukiwarki"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2d5512f",
   "metadata": {},
   "source": [
    "Testy zostały wykonane na bazie artykułów ```simplewiki```, dla artykułów powyżej 100 słów"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "951e1786",
   "metadata": {},
   "source": [
    "## Hasło \"Joseph Stalin\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "827628f3",
   "metadata": {},
   "source": [
    "| Pozycja | Bez SVD                                      | SVD k=100               | SVD k=200                     | SVD k=300                | SVD k=500                | SVD k=1000                   |\n",
    "|---------|-----------------------------------------------|-------------------------|-------------------------------|--------------------------|--------------------------|------------------------------|\n",
    "| 1       | Joseph Stalin (58.7)                          | Vladimir Lenin (80.7)   | Joseph Stalin (80.6)          | Soviet Union (78.1)      | Soviet Union (72.4)      | Joseph Stalin (67.8)         |\n",
    "| 2       | Joseph Smith (57.4)                           | Leon Trotsky (79.7)     | Mikhail Gorbachev (79.7)      | Joseph Stalin (77.8)     | Joseph Stalin (71.5)     | Nikita Khrushchev (57.6)     |\n",
    "| 3       | Joseph (name) (45.3)                          | Joseph Stalin (79.7)    | Nikita Khrushchev (78.1)      | Mikhail Gorbachev (75.4) | Nikita Khrushchev (69.5) | Joseph (name) (55.1)         |\n",
    "| 4       | De-Stalinization (42.7)                       | Nikita Khrushchev (79.0)| Georgy Malenkov (78.0)        | Nikita Khrushchev (74.8) | Yuri Andropov (68.6)     | De-Stalinization (55.1)      |\n",
    "| 5       | Khrushchev's Secret Speech (35.2)             | Nicholas II (78.8)      | Lavrenty Beria (77.8)         | De-Stalinization (74.8)  | De-Stalinization (68.3)  | Georgy Malenkov (54.3)       |\n",
    "| 6       | Saint Joseph's Day (33.5)                     | Catherine II (78.8)     | Ryutin Affair (77.7)          | Georgy Malenkov (74.8)   | Georgy Malenkov (68.2)   | Lavrenty Beria (53.5)        |\n",
    "| 7       | List of people from St. Joseph, Missouri (32.5)| Lavrenty Beria (77.8)   | Hungarian Revolution (77.6)   | Lavrenty Beria (74.5)    | Lavrenty Beria (68.0)    | Khrushchev's Secret Speech (52.8) |\n",
    "| 8       | Joseph: King of Dreams (32.5)                 | Richard Pipes (77.7)    | Perseus (spy) (77.3)          | Ryutin Affair (74.4)     | Ryutin Affair (67.5)     | Sergei Kirov (52.7)          |\n",
    "| 9       | Svetlana Alliluyeva (31.2)                    | Perseus (spy) (77.7)    | Mikhail Kalinin (77.2)        | Mikhail Kalinin (73.7)   | Mikhail Kalinin (66.8)   | Akaki Mgeladze (52.6)        |\n",
    "| 10      | Akaki Mgeladze (31.0)                         | Stepan Bandera (77.7)   | Sixtiers (76.9)               | Sixtiers (73.2)          | Sixtiers (66.6)          | Benjamin (52.6)              |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af4013c2",
   "metadata": {},
   "source": [
    "Dla zapytania „Joseph Stalin” najlepsze rezultaty osiągane są przy zastosowaniu SVD z k = 100–200. Model w tym zakresie trafnie rozpoznaje powiązane postacie i wydarzenia, takie jak Lenin, Trotsky czy Ryutin Affair, oddając historyczny kontekst zapytania.\n",
    "\n",
    "Bez SVD wyniki opierają się głównie na literalnym dopasowaniu słów („Joseph Smith”, „Joseph (name)”), co prowadzi do niskiej trafności semantycznej.\n",
    "\n",
    "Przy wyższych wartościach k (300–1000) model zaczyna zbyt szeroko interpretować zapytanie – na czoło wysuwają się hasła ogólne, jak „Soviet Union”, co osłabia precyzję odpowiedzi."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dcec5e0",
   "metadata": {},
   "source": [
    "## Hasło \"bloody battle in modern times\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14e7eb0e",
   "metadata": {},
   "source": [
    "| Pozycja | Bez SVD                                                          | SVD k=100                    | SVD k=200                                    | SVD k=300                          | SVD k=500                          | SVD k=1000                              |\n",
    "| ------- | ---------------------------------------------------------------- | ---------------------------- | -------------------------------------------- | ---------------------------------- | ---------------------------------- | --------------------------------------- |\n",
    "| 1       | Battle (46.8)                                                    | The Lord of the Rings (79.0) | Battle of Kosovo (76.0)                      | Battle (74.0)                      | Battle (69.2)                      | Battle (66.3)                           |\n",
    "| 2       | Battle of the Philippine Sea (40.7)                              | Longbow (78.0)               | Battle of Verdun (73.9)                      | Battle of Bosworth Field (73.5)    | Battle of Bosworth Field (69.0)    | Battle of Bosworth Field (64.8)         |\n",
    "| 3       | Second Battle of El Alamein (40.2)                               | Jack Dempsey (77.6)          | Battle of Finnburg (73.8)                    | Battle of Verdun (72.3)            | Battle droid (68.9)                | Battle droid (64.2)                     |\n",
    "| 4       | Bloody Sunday (36.4)                                             | Battle of Marathon (77.2)    | Battle of Passchendaele (73.6)               | Second Battle of El Alamein (71.5) | Battle of Tannenberg (1914) (68.8) | Battle of Tannenberg (1914) (63.9)      |\n",
    "| 5       | Battle of Arras (1917) (35.6)                                    | Benedict Arnold (76.9)       | George S. Patton slapping incidents (72.5)   | Battle of Finnburg (71.5)          | Battle of Verdun (68.2)            | Battle of Verdun (63.5)                 |\n",
    "| 6       | First Battle of El Alamein (33.9)                                | Siegfried Sassoon (76.9)     | Feigned retreat (72.1)                       | Battle of Passchendaele (70.4)     | Second Battle of El Alamein (66.5) | Battle of the Catalaunian Plains (62.9) |\n",
    "| 7       | Cristero War (33.3)                                              | Ironclad warship (76.8)      | Battle of Amiens (1918) (71.8)               | Second Battle of Ypres (70.4)      | Battle of Arras (1917) (66.0)      | Second Battle of El Alamein (62.7)      |\n",
    "| 8       | Warfare in eastern Ukraine during the Russo-Ukrainian War (32.5) | Galley (76.4)                | Battle of Haldighati (71.6)                  | Battle of Amiens (1918) (70.3)     | Battle of Amiens (1918) (65.8)     | Battle of Arras (1917) (61.9)           |\n",
    "| 9       | Battle of Amiens (1918) (32.0)                                   | Winged hussars (76.3)        | Lalitaditya's invasion of Tokharistan (71.4) | Battle of Haldighati (69.7)        | Battle of Ypres (65.7)             | Battle of Amiens (1918) (61.5)          |\n",
    "| 10      | Liquid modernity (31.8)                                          | Alexius I (76.3)             | Battle of Bila Tserkva (1626) (71.1)         | Battle of Krusi (69.6)             | Battle of Roncevaux Pass (65.3)    | Battle of Ypres (61.4)                  |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcdc215d",
   "metadata": {},
   "source": [
    "Dla zapytania „bloody battle in modern times” – które jest stosunkowo ogólnym hasłem – wyniki osiągają najlepszą trafność przy zastosowaniu SVD z k = 100–200. W tym zakresie model skutecznie identyfikuje istotne wydarzenia i postacie związane z nowoczesnymi bitwami, takie jak „Battle of Kosovo”, „Battle of Verdun” czy „Battle of Passchendaele”, które miały kluczowe znaczenie w XX wieku. Ponadto pojawiają się postacie związane z historią wojskowości, takie jak „Jack Dempsey” czy „Benedict Arnold”, które także pasują do tematyki nowoczesnych, krwawych bitew.\n",
    "\n",
    "Bez SVD wyniki są głównie efektem dosłownego dopasowania słów kluczowych. Takie hasła jak „Battle of the Philippine Sea” czy „First Battle of El Alamein” pojawiają się, ale nie są w pełni adekwatne do zapytania, ponieważ dotyczą wcześniejszych okresów, co sprawia, że odpowiedzi stają się mniej trafne w kontekście współczesnych konfliktów zbrojnych.\n",
    "\n",
    "Wartości k powyżej 200 (300–1000) powodują, że model zaczyna zbyt szeroko interpretować zapytanie. W tych przypadkach pojawiają się wyniki takie jak „Battle droid”, które mogą być zrozumiane w kontekście „bitew”, ale nie odpowiadają bezpośrednio na zapytanie o „nowoczesne bitwy”, co osłabia precyzję odpowiedzi."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8ce69f7",
   "metadata": {},
   "source": [
    "# Hasło \"crimes against jews\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "872d9726",
   "metadata": {},
   "source": [
    "| Pozycja | Bez SVD                              | SVD k=100                            | SVD k=200                            | SVD k=300                            | SVD k=500                            | SVD k=1000                           |\n",
    "| ------- | ------------------------------------ | ------------------------------------ | ------------------------------------ | ------------------------------------ | ------------------------------------ | ------------------------------------ |\n",
    "| 1       | Crime (51.7)                         | The Holocaust (85.4)                 | The Holocaust (78.9)                 | Antisemitism (71.0)                  | Crime (73.1)                         | Crime (70.6)                         |\n",
    "| 2       | Antisemitism (49.2)                  | Holocaust denial (83.5)              | Antisemitism (77.7)                  | Crimes against humanity (70.9)       | Antisemitism (68.5)                  | Antisemitism (66.6)                  |\n",
    "| 3       | Homicide (48.0)                      | Babi Yar (83.4)                      | Holocaust denial (76.9)              | Antiziganism (70.8)                  | Hate crime (67.4)                    | Hate crime (66.3)                    |\n",
    "| 4       | Jew (47.5)                           | Yigal Amir (83.3)                    | Babi Yar (76.8)                      | Holocaust inversion (70.8)           | White-collar crime (67.0)            | White-collar crime (64.8)            |\n",
    "| 5       | Crimes against humanity (47.0)       | Sayyed Razi Mousavi (82.8)           | Antiziganism (76.8)                  | Iași pogrom (70.6)                   | Crimes against humanity (66.9)       | Crimes against humanity (64.2)       |\n",
    "| 6       | History of the Jews in Europe (46.0) | Yishai Schlissel (81.8)              | Nazi concentration camp (76.5)       | Secondary antisemitism (70.5)        | Holocaust inversion (66.7)           | Holocaust inversion (63.1)           |\n",
    "| 7       | Jews for Jesus (42.0)                | Racism in Poland (81.8)              | Odessa massacre (1941) (76.4)        | Holocaust uniqueness debate (70.4)   | Antisemitic stereotypes (66.3)       | Antisemitic stereotypes (62.9)       |\n",
    "| 8       | Antisemitic stereotypes (41.8)       | Weaponization of antisemitism (81.5) | Iași pogrom (76.1)                   | Weaponization of antisemitism (69.9) | Holocaust uniqueness debate (66.1)   | Secondary antisemitism (61.8)        |\n",
    "| 9       | Anti-Judaism and antisemitism (41.5) | Historical revisionism (81.4)        | Holocaust uniqueness debate (76.1)   | Historical revisionism (69.9)        | Weaponization of antisemitism (65.9) | Weaponization of antisemitism (61.4) |\n",
    "| 10      | Rhineland massacres (40.6)           | Kraków pogrom (81.1)                 | Weaponization of antisemitism (76.0) | Naliboki massacre (69.6)             | Naliboki massacre (65.8)             | Rhineland massacres (61.3)           |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94567cf7",
   "metadata": {},
   "source": [
    "Dla zapytania „crimes against Jews” – które jest dosyć ogólnym hasłem, obejmującym zarówno współczesne, jak i historyczne zbrodnie – najlepsze wyniki osiągane są przy zastosowaniu SVD z k = 100–200. W tym zakresie model skutecznie identyfikuje najważniejsze wydarzenia związane z przemocą wobec Żydów, takie jak „The Holocaust” (85.4) czy „Babi Yar” (83.4), które miały kluczowe znaczenie w historii XX wieku. Ponadto pojawiają się istotne pojęcia związane z antysemityzmem, jak „Holocaust denial” (83.5) czy „Weaponization of antisemitism” (81.5), które trafnie pasują do zapytania o zbrodnie przeciwko Żydom.\n",
    "\n",
    "Bez SVD wyniki są głównie efektem dosłownego dopasowania słów kluczowych. Takie hasła jak „Crime” (51.7) czy „Homicide” (48.0) mogą być powiązane z przemocą, ale nie odnoszą się bezpośrednio do tematyki zbrodni przeciwko Żydom, co sprawia, że odpowiedzi są mniej trafne i bardziej ogólne.\n",
    "\n",
    "Wartości k powyżej 200 (300–1000) powodują, że model zaczyna zbyt szeroko interpretować zapytanie. W tych przypadkach pojawiają się wyniki takie jak „Crime” (73.1) i „Hate crime” (67.4), które mogą być powiązane z przemocą wobec mniejszości, ale są zbyt ogólne i nie odnoszą się bezpośrednio do zbrodni przeciwko Żydom, co osłabia precyzję odpowiedzi. Ponadto, w wyższych wartościach k pojawiają się terminy takie jak „White-collar crime” (67.0), które wydają się mało związane z zapytaniem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "125d0c5c",
   "metadata": {},
   "source": [
    "# Hasło \"the most famous polish people in the world\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "880006ab",
   "metadata": {},
   "source": [
    "| Pozycja | Bez SVD (Wartość)                      | SVD k=100 (Wartość)            | SVD k=200 (Wartość)         | SVD k=300 (Wartość)         | SVD k=500 (Wartość)         | SVD k=1000 (Wartość)        |\n",
    "| ------- | -------------------------------------- | ------------------------------ | --------------------------- | --------------------------- | --------------------------- | --------------------------- |\n",
    "| 1       | Grzegorz Lato (32.7)                   | Principality of Sealand (70.5) | Poland (67.9)               | Poland (65.9)               | Poland (63.5)               | Poland (57.5)               |\n",
    "| 2       | Tomasz Frankowski (31.1)               | Kickboxing (69.5)              | Warsaw (66.9)               | Warsaw (65.9)               | Warsaw (60.5)               | Warsaw (56.0)               |\n",
    "| 3       | Czesław Kiszczak (30.0)                | Universal history (69.3)       | Józef Piłsudski (66.3)      | Euzebiusz Smolarek (64.4)   | Józef Piłsudski (60.2)      | Józef Piłsudski (54.5)      |\n",
    "| 4       | Zygmunt Bauman (28.8)                  | American kickboxing (69.1)     | Grzegorz Lato (64.8)        | Grzegorz Lato (62.9)        | Grzegorz Lato (60.1)        | Grzegorz Lato (54.2)        |\n",
    "| 5       | Jan Kobuszewski (28.7)                 | Shamanism (68.4)               | Józef Kowalski (64.3)       | Józef Kowalski (62.7)       | Józef Kowalski (60.1)       | Józef Kowalski (54.1)       |\n",
    "| 6       | Zbigniew Ścibor-Rylski (28.1)          | Four Freedoms (67.0)           | Jan Parandowski (63.4)      | Jan Parandowski (62.5)      | Jan Parandowski (59.5)      | Jan Parandowski (53.2)      |\n",
    "| 7       | Andrzej Strzelecki (28.0)              | Dariusz Michalczewski (66.3)   | Arkadiusz Milik (63.0)      | Józef Czapski (62.3)        | Józef Czapski (59.0)        | Józef Czapski (52.6)        |\n",
    "| 8       | Adam Zagajewski (27.7)                 | Johnny Ekström (66.1)          | Wilm Hosenfeld (62.6)       | Arkadiusz Milik (62.3)      | Arkadiusz Milik (58.9)      | Arkadiusz Milik (52.6)      |\n",
    "| 9       | Polish People's Army (27.4)            | Charlotte Walker (65.9)        | Reuven Fahn (62.6)          | Wilm Hosenfeld (62.0)       | Wilm Hosenfeld (58.9)       | Wilm Hosenfeld (52.4)       |\n",
    "| 10      | Polish Armed Forces in the East (27.3) | Ekkehard Knobelspies (65.8)    | Włodzimierz Smolarek (62.5) | Włodzimierz Smolarek (61.6) | Włodzimierz Smolarek (58.7) | Włodzimierz Smolarek (52.4) |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d78c3d3e",
   "metadata": {},
   "source": [
    "Przy k=100: Wyniki są bardzo nietrafione - na pierwszych miejscach znajdują się pozycje jak \"Principality of Sealand\" (mikronacja), \"Kickboxing\" czy \"Universal history\", które nie mają bezpośredniego związku z zapytaniem o znanych Polaków.\n",
    "\n",
    "Przy k=200-300: Następuje znaczna poprawa trafności. \"Poland\" pojawia się na pierwszym miejscu, a w top 10 znajduje się wielu znanych Polaków (Józef Piłsudski, Grzegorz Lato, Euzebiusz Smolarek).\n",
    "\n",
    "Przy k=500-1000: Ranking stabilizuje się, choć wartości liczbowe (w nawiasach) stopniowo maleją wraz ze wzrostem k.\n",
    "Trend wartości liczbowych: Ogólnie widać, że wartości liczbowe maleją wraz ze wzrostem parametru k. Przy k=100 najwyższa wartość to 70.5, a przy k=1000 spada do 57.5.\n",
    "\n",
    "SVD skutecznie eliminuje \"zapychacze\" przy wyższych wartościach k (od 200 wzwyż).\n",
    "Porównując wyniki bez SVD z wynikami dla większych wartości k (300-1000), widać jak metoda SVD może przekształcić ranking z listy zawierającej mniej znane osoby (np. Jan Kobuszewski, Andrzej Strzelecki) na listę bardziej reprezentatywną dla zapytania o \"najsłynniejszych Polaków\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "690a3449",
   "metadata": {},
   "source": [
    "## Podsumowanie testów\n",
    "\n",
    "- Niskie wartości k zapewniają precyzyjne i trafne wyniki, dobrze odpowiadające zapytaniom.\n",
    "\n",
    "- Zbyt wysokie wartości k mogą prowadzić do rozmycia wyników, zwiększając liczbę wyników mniej trafnych, przez co dokładność odpowiedzi spada.\n",
    "\n",
    "- SVD z optymalnym k (100–200) pomaga osiągnąć najlepsze dopasowanie semantyczne do zapytania, skutecznie identyfikując kluczowe tematy i elementy zarówno dla zapytań bardzo ogólnych (\"bloody battle in modern times\") jak i bardziej konkretnych (\"Joseph Stalin\")\n",
    "\n",
    "- Czas wykonania zapytania rośnie wraz ze wzrostem k"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "355111fd",
   "metadata": {},
   "source": [
    "# Testy dla zbioru artykułów historycznych z \"normalnej\" wikipedii"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4de5a404",
   "metadata": {},
   "source": [
    "Artykuły pozyskane przez crawler są dużo dłuższe niż te będące na simplewiki, dlatego wyniki dopasowania mogą być inne niż dla simplewiki"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6da7ee85",
   "metadata": {},
   "source": [
    "## Hasło \"fall of Poland\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8ce8274",
   "metadata": {},
   "source": [
    "| **Pozycja** | **Bez SVD (Wartość)**                           | **SVD k=100 (Wartość)**                     | **SVD k=200 (Wartość)**                               | **SVD k=300 (Wartość)**                               | **SVD k=500 (Wartość)**                   |\n",
    "| ----------- | ----------------------------------------------- | ------------------------------------------- | ----------------------------------------------------- | ----------------------------------------------------- | ----------------------------------------- |\n",
    "| 1           | Poland–United States relations (43.1)           | History of Poland (94.7)                    | History of Poland (94.0)                              | History of Poland (93.7)                              | History of Poland (93.1)                  |\n",
    "| 2           | Poland and the European Union (43.0)            | Second Polish Republic (94.7)               | Second Polish Republic (93.9)                         | Second Polish Republic (93.7)                         | Second Polish Republic (93.1)             |\n",
    "| 3           | Poland–United Kingdom relations (38.9)          | Polish–Czechoslovak border conflicts (94.6) | Military history of Poland during World War II (93.0) | Military history of Poland during World War II (92.1) | History of Poland (1795–1918) (90.7)      |\n",
    "| 4           | History of Poland (1795–1918) (37.5)            | Polish–Czechoslovak border conflicts (94.6) | History of Poland (1918–1939) (93.0)                  | History of Poland (1918–1939) (92.1)                  | History of Poland (1918–1939) (89.6)      |\n",
    "| 5           | History of Poland (1918–1939) (37.1)            | Polish–Czechoslovak border conflicts (94.6) | Republic of Poland (93.0)                             | Republic of Poland (92.1)                             | Republic of Poland (89.3)                 |\n",
    "| 6           | Republic of Poland (36.0)                       | Republic of Poland (94.3)                   | Second Republic of Poland (92.3)                      | Second Republic of Poland (91.8)                      | Second Republic of Poland (89.3)          |\n",
    "| 7           | Greater Poland Uprising (disambiguation) (35.8) | Second Republic of Poland (93.8)            | Interwar Poland (92.1)                                | Interwar Poland (91.3)                                | Interwar Poland (89.3)                    |\n",
    "| 8           | Template talk\\:Polish uprisings (32.6)          | Interwar Poland (93.8)                      | Third Polish Republic (92.1)                          | Third Polish Republic (91.1)                          | Third Polish Republic (88.3)              |\n",
    "| 9           | Third Polish Republic (32.4)                    | Polish occupation zone in Germany (93.8)    | Polish contribution to World War II (92.1)            | Polish contribution to World War II (91.1)            | History of Poland under partitions (87.6) |\n",
    "| 10          | History of Poland under partitions (32.3)       | Republic of Poland (94.3)                   | History of Kraków (91.7)                              | History of Kraków (90.6)                              | History of Kraków (87.5)                  |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffd26af6",
   "metadata": {},
   "source": [
    "Bez SVD: Wyniki koncentrują się na relacjach międzynarodowych Polski (z USA, UE, Wielką Brytanią) zamiast na wydarzeniach historycznych związanych z upadkiem państwa.\n",
    "\n",
    "Przy k=100: Nastąpiła radykalna zmiana tematyczna - dominują artykuły o historii Polski i II RP. Występują duplikaty (np. \"Polish–Czechoslovak border conflicts\" na 3 pozycjach) i powtórzenia (\"Republic of Poland\").\n",
    "\n",
    "Przy k=200-300: Ranking się stabilizuje i oferuje większą różnorodność historyczną, obejmując II RP, II wojnę światową i III RP. Eliminuje problematyczne duplikaty z k=100.\n",
    "\n",
    "Przy k=500: Podobne wyniki jak przy k=200-300, ale z nieznacznie niższymi wartościami (87-93). Pojawia się \"History of Poland under partitions\" bezpośrednio związane z tematyką rozbiorów.\n",
    "\n",
    "Widzimy generalnie pogorszenie się jakości wyszukiwań. Wynika to z dużo większej liczby danych i też szumu, który nie został w pełni wyeliminowany.\n",
    "\n",
    "Warto wspomnieć, że Bag Of Words dla ```historywiki``` miał wielkość 1.250.000 co potwierdza duże zaszumienie.\n",
    "\n",
    "Powtarzające się artykuły wynikają ze specyfiki crowlera. Artykuły są identygikowane przez adres url, ale niestety do niektórych artykułów odsyła więcej niż jeden link."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0c091fa",
   "metadata": {},
   "source": [
    "## Hasło \"Relations between Russia and Ukraine\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b47e5cb",
   "metadata": {},
   "source": [
    "| Pozycja | Bez SVD (Wartość)                                                                    | SVD k=100 (Wartość)                                                                                 | SVD k=200 (Wartość)                                                                                 | SVD k=300 (Wartość)                                                                  | SVD k=500 (Wartość)                                                                  |\n",
    "| ------- | ------------------------------------------------------------------------------------ | --------------------------------------------------------------------------------------------------- | --------------------------------------------------------------------------------------------------- | ------------------------------------------------------------------------------------ | ------------------------------------------------------------------------------------ |\n",
    "| 1       | February 2025 United States–Russia summit in Saudi Arabia (55.0)                     | Diplomatic expulsions during the Russo-Ukrainian War (96.6)                                         | Foreign relations of Russia since the Russian invasion of Ukraine (94.6)                            | Non-government reactions to the Russian invasion of Ukraine (93.5)                   | Non-government reactions to the Russian invasion of Ukraine (92.2)                   |\n",
    "| 2       | Non-government reactions to the Russian invasion of Ukraine (54.9)                   | Foreign relations of Russia since the Russian invasion of Ukraine (96.6)                            | Government and intergovernmental reactions to the Russian invasion of Ukraine (94.6)                | Foreign relations of Russia since the Russian invasion of Ukraine (93.5)             | Foreign relations of Russia since the Russian invasion of Ukraine (92.2)             |\n",
    "| 3       | Foreign relations of Russia since the Russian invasion of Ukraine (54.9)             | Government and intergovernmental reactions to the Russian invasion of Ukraine (95.8)                | Reactions to the Russian invasion of Ukraine (94.0)                                                 | Government and intergovernmental reactions to the Russian invasion of Ukraine (92.7) | Government and intergovernmental reactions to the Russian invasion of Ukraine (91.0) |\n",
    "| 4       | Government and intergovernmental reactions to the Russian invasion of Ukraine (52.0) | Reactions to the Russian invasion of Ukraine (95.2)                                                 | Prelude to the Russian invasion of Ukraine (93.5)                                                   | Reactions to the Russian invasion of Ukraine (92.0)                                  | Reactions to the Russian invasion of Ukraine (90.4)                                  |\n",
    "| 5       | Reactions to the Russian invasion of Ukraine (50.8)                                  | Prelude to the Russian invasion of Ukraine (94.9)                                                   | International recognition of the Donetsk People's Republic and the Luhansk People's Republic (93.0) | Prelude to the Russian invasion of Ukraine (91.9)                                    | Prelude to the Russian invasion of Ukraine (90.1)                                    |\n",
    "| 6       | Legality of the Russian invasion of Ukraine (50.5)                                   | Controversy in Russia regarding the legitimacy of eastward NATO expansion (94.8)                    | International reactions to the annexation of Crimea by the Russian Federation (92.9)                | International reactions to the annexation of Crimea by the Russian Federation (91.3) | On conducting a special military operation (89.4)                                    |\n",
    "| 7       | Foreign Relations of Russia since the Russian invasion of Ukraine (50.1)             | International recognition of the Donetsk People's Republic and the Luhansk People's Republic (94.5) | Prelude to the Russian invasion of Ukraine (92.4)                                                   | Prelude to the Russian invasion of Ukraine (91.3)                                    | Prelude to the Russian invasion of Ukraine (88.6)                                    |\n",
    "| 8       | Special relationship (international relations) (49.5)                                | International reactions to the annexation of Crimea by the Russian Federation (94.2)                | Foreign Relations of Russia since the Russian invasion of Ukraine (92.4)                            | Foreign Relations of Russia since the Russian invasion of Ukraine (91.1)             | Foreign Relations of Russia since the Russian invasion of Ukraine (88.6)             |\n",
    "| 9       | List of battles involving the Russian Federation (48.4)                              | Foreign Relations of Russia since the Russian invasion of Ukraine (94.2)                            | Prelude to the 2022 Russian invasion of Ukraine (92.4)                                              | Prelude to the 2022 Russian invasion of Ukraine (91.1)                               | Prelude to the 2022 Russian invasion of Ukraine (88.6)                               |\n",
    "| 10      | Template talk\\:Ukraine–European Union relations (47.3)                               | International reactions to the war in Donbas (94.1)                                                 | International reactions to the war in Donbas (92.4)                                                 | International reactions to the war in Donbas (91.1)                                  | International reactions to the war in Donbas (88.6)                                  |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cec7b40",
   "metadata": {},
   "source": [
    "Bez SVD: Zdominowane przez aktualne wydarzenia polityczne - szczyt USA-Rosja (2025) na pierwszym miejscu, reakcje na inwazję i kwestie prawne konfliktu. Widoczne są też ogólne hasła jak \"Special relationship\" i techniczne wpisy. Brak historycznej perspektywy stosunków dwustronnych.\n",
    "\n",
    "Przy k=100: Znacząca poprawa trafności - koncentracja na dyplomatycznych i międzynarodowych aspektach konfliktu. Pojawia się kontekst historyczny (NATO, Donbas, Krym). Uwzględnione są także ważne punkty zwrotne w relacjach (uznanie republik separatystycznych).\n",
    "\n",
    "Przy k=200: Stabilizacja wyników z naciskiem na relacje międzynarodowe Rosji po inwazji. Więcej kontekstu historycznego (preludium do inwazji) i kluczowych momentów (aneksja Krymu). Widoczne dublowanie niektórych artykułów.\n",
    "\n",
    "Przy k=300: Podobna struktura do k=200, ale z lepszą spójnością bez duplikatów. \"Non-government reactions\" awansuje na pierwsze miejsce.\n",
    "\n",
    "Przy k=500: Pojawia się rosyjska perspektywa (\"special military operation\"). Większy spadek wartości dla niższych pozycji rankingu. Struktura tematyczna pozostaje skupiona na konflikcie."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bd835fd",
   "metadata": {},
   "source": [
    " SVD istotnie poprawia trafność wyników, ale nawet optymalne wartości k=200-300 nie rozwiązują problemu jednostronnego skupienia na konflikcie zbrojnym z pominięciem szerszego kontekstu historycznych stosunków rosyjsko-ukraińskich."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "937a5c9f",
   "metadata": {},
   "source": [
    "# Podsumowanie"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92afd609",
   "metadata": {},
   "source": [
    "### Wnioski:\n",
    "- SVD znacząco poprawia trafność wyników, szczególnie dla bardziej ogólnych zapytań.\n",
    "- Optymalne wartości parametru k (100–300) zapewniają najlepszy balans między precyzją a różnorodnością wyników.\n",
    "- Wyszukiwarka działa skutecznie zarówno na małych, jak i dużych zbiorach danych, choć większe zbiory wymagają bardziej zaawansowanego przetwarzania w celu redukcji szumu.\n",
    "- Projekt demonstruje potencjał technik przetwarzania języka naturalnego (NLP) w budowie wyszukiwarek semantycznych."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
