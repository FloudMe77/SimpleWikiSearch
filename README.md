# WikiSearch Engine 

## Dariusz Marecik

WikiSearch to projekt wyszukiwarki artyku贸w z Wikipedii skupiajcej si na treciach zwizanych z histori. Celem tego projektu jest stworzenie efektywnego narzdzia do przeszukiwania i odnajdywania informacji historycznych, wykorzystujcego techniki przetwarzania jzyka naturalnego oraz redukcji wymiarowoci za pomoc SVD (Singular Value Decomposition) oraz indeksu HNSW (Hierarchical Navigable Small World).
![Frontend look](images/front.png)
### Struktura Projektu

Projekt skada si z kilku kluczowych modu贸w, kt贸re wsp贸pracuj ze sob, aby zapewni funkcjonalno wyszukiwarki:

* **`dump_loader.py`**: Ten skrypt odpowiada za adowanie danych z pliku XML (zrzutu Wikipedii), czyszczenie tekstu artyku贸w oraz zapisywanie ich do bazy danych SQLite.
    * **Czyszczenie tekstu**: Skrypt wykorzystuje bibliotek `mwparserfromhell` do usuwania skadni wiki, a tak偶e wyra偶enia regularne do eliminacji niechcianych element贸w, takich jak miniatury, nadmiarowe spacje czy formatowanie.
    * **Filtrowanie**: Artykuy s filtrowane pod ktem dugoci (minimum 100 s贸w) oraz typu (pomijane s przekierowania i artykuy spoza g贸wnej przestrzeni nazw).
    * **Baza danych**: Dane s przechowywane w tabeli `articles` w bazie `simplewiki2.db` (lub `simplewiki100.db` w przypadku aplikacji Flask), zawierajcej takie pola jak `url`, `title`, `intro` (pierwszy akapit) i `content`.

* **`scraper.py`**: Alternatywny modu do pozyskiwania danych, kt贸ry skanuje Wikipedi (konkretnie strony angielskiej Wikipedii zwizane z histori) za pomoc web scrapingu.
    * **Filtrowanie historyczne**: Scraper identyfikuje artykuy zwizane z histori na podstawie listy s贸w kluczowych (np. 'history', 'ancient', 'war', 'empire') w tytule.
    * **Inteligentne przeszukiwanie**: Wykorzystuje kolejk (deque) do zarzdzania adresami URL do odwiedzenia, przeszukujc kategorie historyczne oraz artykuy z link贸w, unikajc duplikat贸w i niechcianych stron.
    * **Kontrola szybkoci**: Wbudowana jest losowa pauza midzy zapytaniami, aby unikn przeci偶enia serwer贸w Wikipedii.
    * **Zapisywanie postpu**: Stan scrapowania (kolejka, odwiedzone adresy, liczba artyku贸w) jest regularnie zapisywany, co pozwala na wznowienie procesu w razie przerwania.

* **`database_manager.py`**: Klasa odpowiedzialna za zarzdzanie poczeniem z baz danych SQLite. Umo偶liwia pobieranie wszystkich treci artyku贸w oraz konkretnych danych (np. URL, tytu, intro) na podstawie listy identyfikator贸w.

* **`search_engine.py`**: Serce wyszukiwarki. Odpowiada za budowanie modelu TF-IDF (Term Frequency-Inverse Document Frequency) oraz opcjonalne zastosowanie SVD do redukcji wymiarowoci i efektywnego wyszukiwania podobnych dokument贸w.
    * **Modelowanie BOW (Bag of Words)**: Tekst artyku贸w jest przetwarzany na wektory reprezentujce czstotliwo wystpowania s贸w.
    * **TF-IDF**: Wagi s贸w s dostosowywane za pomoc miary IDF, kt贸ra obni偶a znaczenie czsto wystpujcych, a mniej istotnych s贸w.
    * **SVD (Singular Value Decomposition)**: Opcjonalnie, macierz TF-IDF mo偶e by poddana dekompozycji SVD, co pozwala na redukcj wymiarowoci i lepsze uchwycenie ukrytych zale偶noci semantycznych midzy sowami i dokumentami.
    * **HNSW (Hierarchical Navigable Small World)**: Po zastosowaniu SVD, wykorzystywany jest indeks HNSW do szybkiego wyszukiwania najbli偶szych ssiad贸w (artyku贸w) w przestrzeni o zmniejszonej wymiarowoci, co przyspiesza proces wyszukiwania.
    * **Zapisywanie/adowanie modeli**: Macierz TF-IDF i modele SVD/HNSW mog by zapisywane i adowane z plik贸w, co znacznie skraca czas uruchamiania silnika wyszukiwania.

* **`flask_app.py`**: Aplikacja webowa napisana we Flasku, kt贸ra udostpnia interfejs u偶ytkownika do wyszukiwania artyku贸w.
    * **Wyszukiwanie**: Przyjmuje zapytania od u偶ytkownika i przekazuje je do `search_engine_manager` (prawdopodobnie wrapper dla `search_engine.py`), a nastpnie wywietla posortowane wyniki z bazy danych.
    * **Konfiguracja**: Umo偶liwia ustawienie nazwy bazy danych, wartoci `k` dla SVD oraz liczby wynik贸w do wywietlenia.
    * **Pomiar czasu**: Mierzy i wywietla czas potrzebny na wykonanie zapytania.

* **`simplifier.py`**:  mdu odpowiedzialny za upraszczanie s贸w, np. lematyzacj i stemming, przed ich przetworzeniem przez silnik wyszukiwania.

### Foldery w Repozytorium

* **`dump/`**: Ten folder przechowuje zrzuty (dump) Wikipedii w formacie XML, kt贸re s wykorzystywane przez skrypt `dump_loader.py` do pocztkowego zapenienia bazy danych artykuami.
* **`saved_svd/`**: W tym katalogu przechowywane s zapisane modele SVD, takie jak macierze U, D, Vt oraz indeks HNSW. Dziki temu nie ma potrzeby ponownego obliczania SVD przy ka偶dym uruchomieniu aplikacji, co znacznie przyspiesza inicjalizacj silnika wyszukiwania.
* **`saved_data/`**: Ten folder zawiera zapisane struktury danych zwizane z modelem Bag of Words (BOW), takie jak macierz `csc_BOW` (sparse matrix) oraz pliki `.pkl` zawierajce sowniki `number_to_word`, `word_to_number` i macierz diagonaln `idf_diag`. Jest to kluczowe dla szybkiego wczytywania stanu silnika wyszukiwania. W przypadku `scraper.py`, ten folder mo偶e r贸wnie偶 przechowywa pliki `.pkl` do zapisywania i odczytywania stanu procesu scrapowania (kolejka URL-i, odwiedzone strony, liczba przetworzonych artyku贸w).
* **`static/`**: Ten folder jest standardowym miejscem w aplikacjach Flask do przechowywania plik贸w statycznych, takich jak pliki CSS (do stylizowania interfejsu), JavaScript (do interaktywnoci) i obrazy.
* **`templates/`**: Ten folder zawiera szablony HTML (`.html`) dla aplikacji Flask. Szablony te s renderowane przez Flask i wypeniane dynamicznymi danymi, tworzc interfejs u偶ytkownika dla wyszukiwarki (np. strona g贸wna, strona wynik贸w wyszukiwania).

### Uruchomienie Projektu

Aby uruchomi projekt:

1. **Sklonuj repozytorium**:
    ```bash
   git clone https://github.com/FloudMe77/SimpleWikiSearch.git
   ```
2. **Przejd藕 do katalogu z kodem 藕r贸dowym**:
   ```bash
   cd WikiSearchEngine
   ```
3. Upewnij si, 偶e masz zainstalowane wymagane biblioteki. Mo偶na je zainstalowa za pomoc pliku `requirements.txt`:
   ```bash
   pip install -r requirements.txt
   ```

4.  **Przygotowanie danych**:
    * Pobierz zrzut Wikipedii z tej [strony](https://dumps.wikimedia.org/backup-index.html) (np. `simplewiki-latest-pages-articles.xml` dla angielskiej Simple Wikipedii) i umie go w folderze `dump/`.
    * Uruchom `python dump_loader.py` aby zapeni baz danych `simplewiki200.db` (lub zmie nazw bazy danych w `flask_app.py` na `simplewiki100.db`, aby bya zgodna z domyln konfiguracj Flask).
    * Alternatywnie, mo偶esz uruchomi `python scraper.py` aby zapeni baz danych `historywiki.db` artykuami historycznymi z angielskiej Wikipedii.

5.  **Inicjalizacja silnika wyszukiwania**:
    * Przy pierwszym uruchomieniu `flask_app.py`, silnik `search_engine.py` zbuduje macierz TF-IDF i ewentualnie wykona dekompozycj SVD, zapisujc wyniki w folderach `saved_data/` i `saved_svd/`.

6.  **Uruchomienie aplikacji Flask**:
    * Uruchom `python flask_app.py`. Aplikacja bdzie dostpna pod adresem `http://0.0.0.0:8000/`.

Ten projekt stanowi kompleksowe rozwizanie do budowy wyszukiwarki treci, od pozyskiwania danych, przez ich przetwarzanie i indeksowanie, a偶 po udostpnianie interfejsu u偶ytkownikowi.

![alt text](images/animation.gif)